<script lang="ts">
  import ResultView from "$lib/components/ResultView.svelte";
  import AudioUpload from "$lib/components/AudioUpload.svelte";
  import { apiKeyStore } from "$lib/stores/api";
  import { interviewAnalysisInputStore } from '$lib/stores/api';
  import { buildInterviewAnalysisPrompt } from "@prompt-hub/prompt";
  import { useAIStream } from '$lib/hooks/useAIStream';

  let audioFile: File | null = null;
  let transcribedText = '';
  $: transcribedText = $interviewAnalysisInputStore;
  $: interviewAnalysisInputStore.set(transcribedText);
  let isTranscribing = false;
  let transcriptionProgress = 0;

  $: aiStream = useAIStream("interview-analysis");
  $: state = aiStream.state;
  $: ({ progress, status, result, error } = $state);
  $: statusTip = aiStream.statusTip;
  $: output = result || error || "";
  $: loading = status !== "done" && status !== "error" && status !== "idle";

  // å¤„ç†éŸ³é¢‘ä¸Šä¼ 
  const handleAudioUpload = (file: File) => {
    audioFile = file;
    transcribedText = '';
    interviewAnalysisInputStore.set('');
    aiStream.reset();
  };

  // å¼€å§‹è½¬å½•
  const startTranscription = async () => {
    if (!audioFile) return;

    // æ£€æŸ¥API Key
    const apiKey = $apiKeyStore;
    if (!apiKey) {
      alert("è¯·å…ˆé…ç½®API Key");
      return;
    }

    isTranscribing = true;
    transcriptionProgress = 0;

    try {
      console.log("å¼€å§‹è½¬å½•ï¼ŒéŸ³é¢‘æ–‡ä»¶ä¿¡æ¯:", {
        size: audioFile.size,
        type: audioFile.type,
        name: audioFile.name,
        lastModified: audioFile.lastModified,
      });

      transcriptionProgress = 10;

      // å‡†å¤‡FormData
      const formData = new FormData();
      formData.append("model", "FunAudioLLM/SenseVoiceSmall");
      formData.append("file", audioFile);

      transcriptionProgress = 30;

      // è°ƒç”¨SiliconFlowè¯­éŸ³è½¬æ–‡æœ¬API
      const response = await fetch(
        "https://api.siliconflow.cn/v1/audio/transcriptions",
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${apiKey}`,
          },
          body: formData,
        }
      );

      transcriptionProgress = 70;

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`APIè¯·æ±‚å¤±è´¥ (${response.status}): ${errorText}`);
      }

      const data = await response.json();
      console.log("è½¬å½•ç»“æœ:", data);

      transcriptionProgress = 90;

      // æå–è½¬å½•æ–‡æœ¬
      transcribedText = data.text || "";

      transcriptionProgress = 100;

      console.log("æœ€ç»ˆè½¬å½•æ–‡æœ¬:", transcribedText);

      if (!transcribedText.trim()) {
        alert(
          `æœªèƒ½è¯†åˆ«åˆ°è¯­éŸ³å†…å®¹ã€‚\néŸ³é¢‘ä¿¡æ¯ï¼š\n- æ–‡ä»¶å¤§å°: ${(audioFile.size / 1024 / 1024).toFixed(2)} MB\n- æ–‡ä»¶ç±»å‹: ${audioFile.type}\n- æ–‡ä»¶å: ${audioFile.name}\n\nè¯·å°è¯•ï¼š\nâ€¢ ä½¿ç”¨WAVæˆ–MP3æ ¼å¼\nâ€¢ ç¡®ä¿éŸ³é¢‘æ¸…æ™°ä¸”éŸ³é‡é€‚ä¸­\nâ€¢ æ£€æŸ¥éŸ³é¢‘æ—¶é•¿ä¸è¦å¤ªçŸ­`
        );
      }
    } catch (error) {
      console.error("è½¬å½•å¤±è´¥:", error);
      let errorMessage = "è½¬å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ï¼š\n";
      const errorMsg = error instanceof Error ? error.message : String(error);
      if (errorMsg.includes("401") || errorMsg.includes("403")) {
        errorMessage += "â€¢ API Keyæ˜¯å¦æ­£ç¡®\nâ€¢ API Keyæ˜¯å¦æœ‰æ•ˆ";
      } else if (errorMsg.includes("network") || errorMsg.includes("fetch")) {
        errorMessage += "â€¢ ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\nâ€¢ æ˜¯å¦èƒ½è®¿é—®SiliconFlow API";
      } else if (errorMsg.includes("format") || errorMsg.includes("file")) {
        errorMessage += "â€¢ éŸ³é¢‘æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®\nâ€¢ å»ºè®®ä½¿ç”¨ MP3 æˆ– WAV æ ¼å¼";
      } else {
        errorMessage += `â€¢ å…·ä½“é”™è¯¯: ${errorMsg}`;
      }
      alert(errorMessage);
    } finally {
      isTranscribing = false;
    }
  };

  // å¼€å§‹AIåˆ†æ
  const startAnalysis = async () => {
    if (!transcribedText.trim()) {
      alert("è¯·å…ˆä¸Šä¼ éŸ³é¢‘å¹¶å®Œæˆè½¬å½•");
      return;
    }

    const prompt = buildInterviewAnalysisPrompt(transcribedText);
    await aiStream.invoke(prompt);
  };
</script>

<svelte:head>
  <title>é¢è¯•è¡¨ç°åˆ†æ - Prompt Hub</title>
</svelte:head>

<div class="max-w-7xl mx-auto py-6">
  <!-- é¡µé¢æ ‡é¢˜ -->
  <div class="text-center mb-8">
    <div
      class="inline-flex items-center justify-center w-16 h-16 bg-gradient-to-br from-purple-500 to-pink-600 rounded-2xl shadow-strong mb-4"
    >
      <span class="text-white text-2xl">ğŸ¤</span>
    </div>
    <h1 class="text-3xl font-bold text-neutral-800 mb-2">é¢è¯•è¡¨ç°åˆ†æ</h1>
    <p class="text-neutral-600 max-w-2xl mx-auto">
      ä¸Šä¼ é¢è¯•å½•éŸ³ï¼Œå°†ä¸ºä½ æä¾›ä¸“ä¸šçš„è¡¨ç°åˆ†æå’Œæ”¹è¿›å»ºè®®
    </p>
  </div>

  <!-- ä¸»è¦å†…å®¹åŒºåŸŸ -->
  <div class="grid grid-cols-1 lg:grid-cols-2 gap-6">
    <!-- å·¦ä¾§ï¼šéŸ³é¢‘ä¸Šä¼ å’Œè½¬å½• -->
    <div class="space-y-6">
      {#if transcribedText}
        <div
          class="bg-white/70 backdrop-blur-sm rounded-2xl p-6 shadow-soft border border-white/20"
        >
          <h3
            class="text-lg font-semibold text-neutral-800 mb-4 flex items-center"
          >
            <span class="w-2 h-2 bg-blue-500 rounded-full mr-3"></span>
            ğŸ”„ è½¬å½•ç»“æœ
          </h3>
          <textarea
            bind:value={transcribedText}
            class="w-full h-40 p-3 border border-neutral-300 rounded-lg resize-none focus:ring-2 focus:ring-blue-500 focus:border-transparent"
            placeholder="è½¬å½•çš„æ–‡æœ¬å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ..."
          ></textarea>
        </div>
      {/if}
      <!-- éŸ³é¢‘ä¸Šä¼  -->
      <div
        class="bg-white/70 backdrop-blur-sm rounded-2xl p-6 shadow-soft border border-white/20"
      >
        <h3
          class="text-lg font-semibold text-neutral-800 mb-4 flex items-center"
        >
          <span class="w-2 h-2 bg-purple-500 rounded-full mr-3"></span>
          ğŸ“ ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
        </h3>
        <AudioUpload onUpload={handleAudioUpload} />

        {#if audioFile}
          <div class="mt-4 p-3 bg-green-50 rounded-lg border border-green-200">
            <p class="text-green-700 text-sm">
              âœ… å·²é€‰æ‹©æ–‡ä»¶: {audioFile.name}
            </p>
          </div>
        {/if}
        
        <!-- æ“ä½œæŒ‰é’® -->
        <div class="flex flex-col sm:flex-row gap-3 mt-4">
          <button
            on:click={startTranscription}
            disabled={!audioFile || isTranscribing}
            class="flex-1 bg-gradient-to-r from-blue-500 to-purple-600 text-white px-6 py-3 rounded-xl font-medium hover:from-blue-600 hover:to-purple-700 disabled:opacity-50 disabled:cursor-not-allowed transition-all duration-200"
          >
            {#if isTranscribing}
              è½¬å½•ä¸­... ({transcriptionProgress}%)
            {:else}
              å¼€å§‹è½¬å½•
            {/if}
          </button>

          <button
            on:click={startAnalysis}
            disabled={!transcribedText.trim() || loading}
            class="flex-1 bg-gradient-to-r from-green-500 to-emerald-600 text-white px-6 py-3 rounded-xl font-medium hover:from-green-600 hover:to-emerald-700 disabled:opacity-50 disabled:cursor-not-allowed transition-all duration-200"
          >
            {#if loading}
              åˆ†æä¸­...
            {:else}
              å¼€å§‹åˆ†æ
            {/if}
          </button>
        </div>
      </div>

      <!-- è½¬å½•ç»“æœ -->
    </div>

    <!-- å³ä¾§ï¼šåˆ†æç»“æœ -->
    <div>
      <ResultView text={output} />
    </div>
  </div>
</div>
